{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Backpropagation | Log #005\"\n",
    "description: How does the NN learn ?\"\n",
    "date: 2025-01-05\n",
    "author: \"Hemanth KR\"\n",
    "categories: [Vision]\n",
    "image: \"thumbnails/005.jpg\"\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Previously we saw how to build a neural network that does image classification. Before we explore different neural network architectures, let's spend some time understanding how the NN actually learns.  \n",
    "\n",
    "[Source Link to checkout.](https://www.dataversity.net/brief-history-deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By 2011, the speed of GPUs had increased significantly, making it possible to train convolutional neural networks “without” the layer-by-layer pre-training. With the increased computing speed, it became obvious deep learning had significant advantages in terms of efficiency and speed. One example is AlexNet, a convolutional neural network whose architecture won several international competitions during 2011 and 2012. Rectified linear units were used to enhance the speed and dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
