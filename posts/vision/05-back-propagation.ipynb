{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Backpropagation | Log #005\"\n",
    "description: \"How does the NN learn ?\"\n",
    "date: 2025-01-05\n",
    "author: \"Hemanth KR\"\n",
    "categories: [Vision]\n",
    "image: \"thumbnails/005.jpg\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Previously, we saw how to build a neural network that does image classification. Before we explore different neural network architectures and types of problems in computer vision, let's spend some time understanding how the neural network actually learns.\n",
    "\n",
    "From my limited understanding, arguably the most important algorithm that we have come up with throughout history could be Backpropagation. Without the ability to learn non-linear properties from a dataset efficiently, neural networks might not have been so useful to us. So understanding it very crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The core of backpropagation involves calculating the partial derivative of the cost function *C* with respect to each weight *w* in the network:\n",
    "\n",
    "$$ ∂C/∂w $$​\n",
    " \n",
    "This gradient tells us how much a small change in each weight affects the overall error.\n",
    "\n",
    "During the neural network's training process, the algorithm has two phases:\n",
    "\n",
    "(@) Forward Pass:\n",
    "    Input data is passed through the network. As the data passes through the layers, each neuron will apply their weights, biases and activation functions. The ouput is produced depending on the final layer activation functions of the neurons.\n",
    "\n",
    "(@) Backward Pass:\n",
    "    The error between the desired output and network's output is calculated using the loss function. This error is propagated backwards through the network layer by layer. Using the chain rule, the gradients of the error for each weight is calculated. And finally weights are updated based on these gradients and a learning rate.\n",
    "\n",
    "This whole process is repeated multiple times which is called epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "Key thing to note here is that the weights are updated using an optimization algorithm called gradient descent. There are many ways to implement this depending on the type of problem and dataset size. And there are also many types of loss functions and activation functions. These are crutial to understanding the architecture of a Neural Network. We will look at all these functions in the upcoming blogs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
